3/24

ppt 12페이지까지 학습

# 파이썬을 이용한 빅데이터 처리





## 1. urllib 패키지를 활용한 웹 페이지 요청





## 2. requests 패키지를 활용한 웹 페이지 요청

### requests 패키지란?

- Kenneth Reitz에 의해 개발된 파이썬 라이브러리
- HTTP프로토콜과 관련된 기능 지원
- 아나콘다에 기본적으로 설치되어 있지만 가상환경을 만들었기 때문에 별도로 설치함
  - `conda install requests` 또는 `pip install requests`

### requests.request() 함수

- requests 패키지의 대표 함수
- HTTP 요청을 서버에 보내고 응답을 받아오는 기능 지원

| urllib 패키지                                    | requests 패키지                                              |
| ------------------------------------------------ | ------------------------------------------------------------ |
| 인코딩하여 바이너리 형태로 데이터 전송           | 딕셔너리 형태로 데이터 전송                                  |
| 요청 방식(GET, POST)에 따라서 구현 방법이 달라짐 | requests() 함수 호출시 요청 메소드(GET, POST)를 명시하여 요청 |

#### `requests.request(method, url, **kwargs)`

- **method** : 요청 방식 지정(GET, POST, HEAD, PUT, DELETE, OPTIONS)
  - 대부분 GET, POST 방식을 사용
- **url** : 요청할 대상 URL 문자열 지정
- params : [선택적] 요청 시 전달할 Query 문자열 지정
  (딕셔너리, 튜플리스트, 바이트열 가능)
- data : [선택적] 요청 시 바디에 담아서 전달할 요청 파라미터 지정
  (딕셔너리, 튜플리스트, 바이트열 가능)
- json : [선택적] 요청 시 바디에 담아서 전달할 JSON 타입의 객체 지정
- auth : [선택적] 인증처리(로그인)에 사용할 튜플 지정



#### requests.request() 함수에 요청 방식을 지정하여 호출하는 것과 동일

- requests.get(url, **params**=None, **kwargs)
- requests.post(url, **data**=None, **json**=None, **kwargs)
- requests.head(url, **kwargs)
- requests.put(url, data=None, **kwargs)
- requests.patch(url, data=None, **kwargs)
- requests.delete(url, **kwargs)



#### GET 방식 요청은 다음 두 가지 함수 중 하나를 호출하여 처리 가능

```
requests.request('GET', url, **kwargs)
[ kwargs ] 
params – (선택적) 요청 시 전달할 Query 문자열을 지정합니다. 
requests.get(url, params=None, **kwargs)
```

- Query 문자열을 포함하여 요청 : params 매개변수에 딕셔너리, 튜플리스트, 바이트열(bytes) 형식으로 전달
- Query 문자열을 포함하지 않는 요청: params 매개변수의 설정 생략

#### POST 방식 요청은 다음 두 가지 함수 중 하나를 호출하여 처리 가능

```
requests.request(‘POST', url, **kwargs)
[ kwargs ]
data – (선택적) 요청 시 바디에 담아서 전달할 요청 파라미터를 지정합니다.
json – (선택적) 요청 시 바디에 담아서 전달할 JSON 타입의 객체를 지정합니다.
requests.post(url, params=None, **kwargs)
```

#### data 매개변수나 json 매개변수로 요청 파라미터를 지정하여 요청하는 것이 일반적

- data 매개변수 : 딕셔너리, 튜플리스트 형식, 바이트열(bytes) 형식으로 지정
- json 매개변수 : JSON 객체 형식 지정



#### requests.request(), requests.get(), requests.head(), requests.post() 함수 모두 리턴 값은 `requests.models.Response`객체

1. Text
   - **문자열** 형식으로 응답 콘텐츠 추출
   - 추출 시 사용되는 문자 셋은 'ISO-8859-1'이므로 'utf-8' 이나 'euc-kr' 문자 셋으로 작성된 콘텐츠 추출 시 한글이 깨지는 현상 발생
   - 추출 전 응답되는 콘텐츠의 문자 셋 정보를 읽고 `r.encoding = 'utf-8'`와 같이 설정한 후 추출
2. Content
   - **바이트열** 형식으로 응답 콘텐츠 추출
   - 응답 콘텐츠가 이미지와 같은 바이너리 형식인 경우 사용
   - 한글이 들어간 문자열 형식인 경우 `r.content.decode('utf-8')`를 사용해서 디코드 해야 함



## 3. BeautifulSoup

- HTML 및 XML 파일에서 데이터를 추출하기 위한 파이썬 라이브러리
- 파이썬에서 기본적으로 제공하는 라이브러리가 아니므로 별도의 설치가 필요하지만 Anaconda에는 BeautifulSoup 패키지가 Site-packages로 설치되어 있음
- HTML 및 XML 파일의 내용을 읽을 때 다음 파서(Parser) 이용
  - html.parser
  - lxml
  - lxml-xml
  - html5lib
- 파이썬이 내장하고 있는 파서를 사용해도 되고, 좀 더 성능이 좋은 파서를 추가로 설치해서 사용해도 됨



### HTML 파싱

	1. BeautifulSoup의 메인 API인 bs4 모듈에서 `BeautifulSoup()` 함수 임포트
 	2. 파싱할 HTML 문서와 파싱에 사용할 파서(구문 분석기)를 지정하여 호출하면, **bs4.BeautifulSoup** 객체 리턴
 	3. HTML 문서에 대한 파싱이 끝나면 트리 구조 형식으로 DOM 객체들이 생성되며, bs4.BeautifulSoup 객체를 통해 접근 가능

```
from bs4 import BeautifulSoup
bs = BeautifulSoup(html_doc, 'html.parser')
bs = BeautifulSoup(html_doc, 'lxml')
bs = BeautifulSoup(html_doc, 'lxml-xml')
bs = BeautifulSoup(html_doc, 'html5lib')
```

- 패키지 설치

```
conda install lxml
conda install html5lib
```



### bs4.BeautifulSoup 객체의 태그 접근 방법

- HTML 문서를 파싱하고 bs4.BeautifulSoup 객체 생성

```
bs = BeautifulSoup(html_doc, 'html.parser')
```

- `<html>`, `<head>`태그와 `<body>` 태그는 제외하고 접근하려는 태그에 **계층 구조**를 적용하여 태그명을 `.` 연산자와 함께 사용

```
bs.태그명
bs.태그명.태그명
bs.태그명.태그명.태그명
```

- HTML 문서의 내용을 파싱하여 BeautifulSoup 객체 생성